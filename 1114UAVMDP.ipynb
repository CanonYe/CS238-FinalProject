{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using POMDPs\n",
    "using Random \n",
    "using Parameters\n",
    "using StaticArrays\n",
    "using Distributions\n",
    "using MCTS\n",
    "using POMDPSimulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UAVMDP"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const Vec2 = SVector{2, Float64}\n",
    "const Vec3 = SVector{3, Float64}\n",
    "\n",
    "struct mystate\n",
    "    uavPose::Vec3\n",
    "    uavHeading::Float64 # radius\n",
    "    targetPose::Vec2\n",
    "end\n",
    "\n",
    "struct myaction\n",
    "    xy_speed::Float64 # m/s\n",
    "    z_speed::Float64\n",
    "    angle::Float64 # radius\n",
    "end\n",
    "\n",
    "@with_kw mutable struct UAVMDP <: MDP{mystate, myaction}\n",
    "\n",
    "    target_velocity::Vec2 = SVector(0.2,0.2)\n",
    "    target_std::Float64 = 0.1\n",
    "\n",
    "    r_outScene::Float64 = -70\n",
    "    r_action::Float64 = -0.1\n",
    "    r_reach::Float64 = 100\n",
    "\n",
    "    discount::Float64 = 0.95\n",
    "    \n",
    "    boundary::Int = 30\n",
    "    landing_r::Int = 1\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "function POMDPs.isterminal(p::UAVMDP,s::mystate)\n",
    "    condition1 = (sqrt((s.uavPose[1]-s.targetPose[1])^2 + (s.uavPose[2]-s.targetPose[2])^2 + s.uavPose[3]^2) < p.landing_r)\n",
    "    condition2 = abs(s.uavPose[1]) > p.boundary || abs(s.uavPose[2])>p.boundary || s.uavPose[3]<0 || s.uavPose[3]>p.boundary\n",
    "    condition = condition1 || condition2\n",
    "#     @show abs(s.uavPose[1]) > p.boundary\n",
    "#     @show abs(s.uavPose[2]) > p.boundary\n",
    "#     @show abs(s.uavPose[3]) > p.boundary\n",
    "#     @show condition1\n",
    "#     @show condition2\n",
    "#     @show condition\n",
    "    return condition\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "function POMDPs.generate_s(p::UAVMDP, s::mystate, a::myaction)\n",
    "    \n",
    "    # calculate target state\n",
    "    target_move = p.target_velocity\n",
    "    sensor_noise = rand(Normal(0, p.target_std), 2)\n",
    "    curr_targ = s.targetPose + target_move + sensor_noise\n",
    "    \n",
    "    # calculate UAV state\n",
    "    curr_angle = s.uavHeading + a.angle\n",
    "    curr_angle = curr_angle%(2*pi)\n",
    "    xy_dt_distance = a.xy_speed*SVector(cos(curr_angle), sin(curr_angle)) # careful\n",
    "    z_dt_distance = a.z_speed\n",
    "    xyz_dt_distance = SVector(xy_dt_distance[1], xy_dt_distance[2], z_dt_distance)\n",
    "    curr_pos = s.uavPose + xyz_dt_distance\n",
    "    return mystate(curr_pos, curr_angle, curr_targ)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myreward (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function myreward(p::UAVMDP, s::mystate, a::myaction)\n",
    "    \n",
    "    distance_to_target = sqrt((s.uavPose[1]-s.targetPose[1])^2 + (s.uavPose[2]-s.targetPose[2])^2 + s.uavPose[3]^2)\n",
    "    \n",
    "    reward = p.r_action + 1/(distance_to_target+1)\n",
    "\n",
    "    if abs(s.uavPose[1]) > p.boundary || abs(s.uavPose[2])>p.boundary || s.uavPose[3]<0 || s.uavPose[3]>p.boundary\n",
    "        reward = reward + p.r_outScene\n",
    "    end\n",
    "\n",
    "    if distance_to_target < p.landing_r\n",
    "        reward = reward + p.r_reach\n",
    "    end\n",
    "    return reward\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "function POMDPs.actions(p::UAVMDP)\n",
    "    action_space = [myaction(i, j, k) for i=-2.0:0.5:2.0,j=-pi:pi/5:pi,k=-2:0.5:2]\n",
    "    return action_space\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "function POMDPs.generate_sr(p::UAVMDP, s::mystate, a::myaction, rng::AbstractRNG)\n",
    "    sp = generate_s(p, s, a)\n",
    "    r = myreward(p, s, a)\n",
    "    return sp, r\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UAVMDP\n",
       "  target_velocity: SArray{Tuple{2},Float64,1,2}\n",
       "  target_std: Float64 0.1\n",
       "  r_outScene: Float64 -70.0\n",
       "  r_action: Float64 -0.1\n",
       "  r_reach: Float64 100.0\n",
       "  discount: Float64 0.95\n",
       "  boundary: Int64 30\n",
       "  landing_r: Int64 1\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POMDPs.initialstate_distribution(p::UAVMDP) = mystate(SVector(1,1,1),0,SVector(0,0))\n",
    "POMDPs.discount(p::UAVMDP) = p.discount\n",
    "solver = MCTSSolver(n_iterations=100, depth=100, exploration_constant=15.0)\n",
    "UAV = UAVMDP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = solve(solver, UAV);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myaction(-1.5, -3.141592653589793, -1.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###trial\n",
    "a = action(policy,mystate(SVector(10,10,10),0,SVector(0,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0-element Array{Any,1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uav_poses = [] # Vector of sequential uav poses\n",
    "target_poses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward_sum = 1.668180203508147\n",
      "current_state = mystate([3.17898, 5.26101, 4.14159], -1.1504440784612413, [1.62895, 2.1072])\n",
      "current_action = myaction(-1.0, 2.5132741228718345, -2.0)\n",
      "terminate = false\n",
      "reward_sum = 3.801857844539914\n",
      "current_state = mystate([3.96864, 5.24708, 1.62832], -2.3008881569224826, [3.38247, 4.73232])\n",
      "current_action = myaction(-2.0, -1.8849555921538759, -2.0)\n",
      "terminate = false\n",
      "reward_sum = 5.680780625265703\n",
      "current_state = mystate([4.77622, 4.56009, 2.88496], -3.451332235383724, [5.66995, 6.41097])\n",
      "current_action = myaction(-1.5, 0.0, -2.0)\n",
      "terminate = false\n",
      "reward_sum = 7.375578435369133\n",
      "current_state = mystate([9.5788, 9.33057, 0.371681], -4.601776313844965, [7.90911, 8.87969])\n",
      "current_action = myaction(1.5, -1.8849555921538759, -2.0)\n",
      "terminate = false\n",
      "reward_sum = 9.338570799362\n",
      "current_state = mystate([8.78508, 11.0239, 2.88496], -5.7522203923062065, [9.41247, 10.7758])\n",
      "current_action = myaction(-0.5, 1.8849555921538759, -2.0)\n",
      "terminate = false\n",
      "reward_sum = 10.141445247210022\n",
      "current_state = mystate([7.99417, 12.0337, 2.88496], -0.6194791635878616, [10.9372, 12.4681])\n",
      "current_action = myaction(1.5, -1.2566370614359172, -2.0)\n",
      "terminate = false\n",
      "reward_sum = 11.554495081798247\n",
      "current_state = mystate([11.842, 13.2803, 4.14159], -1.769923242049103, [12.8612, 14.4227])\n",
      "current_action = myaction(0.5, 2.5132741228718345, -2.0)\n",
      "terminate = false\n",
      "reward_sum = 13.07558367436508\n",
      "current_state = mystate([15.0812, 14.3765, 0.371681], -2.920367320510344, [14.7941, 16.5138])\n",
      "current_action = myaction(-0.5, -1.2566370614359172, -2.0)\n",
      "terminate = false\n",
      "reward_sum = 14.423612474498245\n",
      "current_state = mystate([17.6318, 18.1848, 2.25664], -4.0708113989715855, [17.096, 18.6749])\n",
      "current_action = myaction(1.5, -3.141592653589793, -2.0)\n",
      "terminate = false\n",
      "reward_sum = 15.780965717523395\n",
      "current_state = mystate([20.7442, 20.7084, 0.371681], -5.221255477432827, [19.0852, 20.6157])\n",
      "current_action = myaction(2.0, -2.5132741228718345, -2.0)\n",
      "terminate = false\n",
      "reward_sum = 17.87394030183793\n",
      "current_state = mystate([20.4283, 21.5711, 0.371681], -0.08851424871448188, [21.4788, 22.9])\n",
      "current_action = myaction(-1.0, 0.0, -2.0)\n",
      "terminate = false\n",
      "reward_sum = 19.459188715490196\n",
      "current_state = mystate([22.1376, 22.2687, 1.0], -1.2389583271757232, [23.5369, 24.8186])\n",
      "current_action = myaction(0.5, -3.141592653589793, -2.0)\n",
      "terminate = false\n",
      "reward_sum = 20.18040117884227\n",
      "current_state = mystate([23.3733, 24.9983, 4.14159], -2.3894024056369645, [25.888, 26.9721])\n",
      "current_action = myaction(0.0, -1.2566370614359172, -2.0)\n",
      "terminate = false\n",
      "reward_sum = 21.53029826484165\n",
      "current_state = mystate([26.5447, 27.109, 0.371681], -3.539846484098206, [28.0951, 28.5235])\n",
      "current_action = myaction(-1.0, -1.2566370614359172, -2.0)\n",
      "terminate = false\n",
      "reward_sum = 23.101533353672234\n",
      "current_state = mystate([28.4639, 29.2146, 2.25664], -4.690290562559447, [30.22, 30.7902])\n",
      "current_action = myaction(0.5, 0.6283185307179586, -2.0)\n",
      "terminate = false\n",
      "reward_sum = 24.487718477713216\n",
      "current_state = mystate([29.7526, 29.4186, 1.62832], -5.840734641020688, [32.0214, 32.8937])\n",
      "current_action = myaction(0.0, 0.6283185307179586, -2.0)\n",
      "terminate = false\n",
      "reward_sum = 25.02671681433544\n",
      "current_state = mystate([29.1122, 29.8218, 2.25664], -0.7079934123023435, [33.7087, 34.6595])\n",
      "current_action = myaction(0.0, 0.0, -2.0)\n",
      "terminate = false\n",
      "reward_sum = 25.187743368127254\n",
      "current_state = mystate([29.6286, 31.4106, -1.51327], -1.3584374907635848, [35.9279, 36.8223])\n",
      "current_action = myaction(-1.5, -3.141592653589793, -1.5)\n",
      "terminate = true\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "terminate = false\n",
    "reward_sum = 0\n",
    "\n",
    "current_state = mystate(SVector(1,1,1),0,SVector(0,0)) ##initialize state\n",
    "\n",
    "while i<1000 && !terminate\n",
    "    current_action = action(policy,current_state)\n",
    "    current_reward = myreward(UAV, current_state, current_action)\n",
    "    current_state = generate_s(UAV, current_state, current_action)\n",
    "    push!(uav_poses, current_state.uavPose)\n",
    "    push!(target_poses, current_state.targetPose)\n",
    "    terminate = isterminal(UAV,current_state)\n",
    "    reward_sum = reward_sum + current_reward\n",
    "    i=i+1\n",
    "\n",
    "    if i%10==0\n",
    "        @show reward_sum\n",
    "        @show current_state\n",
    "        @show current_action\n",
    "        @show terminate\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DelimitedFiles\n",
    "writedlm( \"uvapos.csv\", uav_poses)\n",
    "writedlm( \"targetpos.csv\", target_poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
